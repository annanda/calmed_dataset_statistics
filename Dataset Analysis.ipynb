{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e09cb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import altair as alt\n",
    "\n",
    "\n",
    "# configuration for graphics\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "# rcParams['figure.figsize'] = 14, 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a245ea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "PROJECT_ROOT = os.path.dirname(NOTEBOOK_DIR)\n",
    "\n",
    "sys.path.append(PROJECT_ROOT) # make my_module available to import\n",
    "\n",
    "from dataset_statistics.utils import (\n",
    "    COLOURS,\n",
    "    EMOTIONS,\n",
    "    add_video_part_column_to_dataframes, \n",
    "    get_value_count_dict, \n",
    "    generate_dic_to_plot, \n",
    "    create_whole_session_dict_values,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7ee78",
   "metadata": {},
   "source": [
    "# Emotion Zones distribution over session 1 \n",
    "Each plot represents a 5 minutes period of time, each entry is a window of 0.4 seconds (400 miliseconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b362b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all dataframes (session 1)\n",
    "df_1 = pd.read_csv('datasets/participant_1/study_20210526_01_01.mp4.csv')\n",
    "df_2 = pd.read_csv('datasets/participant_1/study_20210526_01_02.mp4.csv')\n",
    "df_3 = pd.read_csv('datasets/participant_1/study_20210526_01_03.mp4.csv')\n",
    "df_4 = pd.read_csv('datasets/participant_1/study_20210526_01_04.mp4.csv')\n",
    "df_5 = pd.read_csv('datasets/participant_1/study_20210526_01_05.mp4.csv')\n",
    "df_6 = pd.read_csv('datasets/participant_1/study_20210526_01_06.mp4.csv')\n",
    "df_7 = pd.read_csv('datasets/participant_1/study_20210526_01_07.mp4.csv')\n",
    "\n",
    "\n",
    "frames = [df_1, df_2, df_3, df_4, df_5, df_6, df_7]\n",
    "\n",
    "frames = add_video_part_column_to_dataframes(frames)\n",
    "\n",
    "frames_dict = create_whole_session_dict_values(frames)\n",
    "\n",
    "frames_dict\n",
    "df = pd.DataFrame(frames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3286cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-b6868080938b40179efa20a8a0d5d009\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b6868080938b40179efa20a8a0d5d009\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b6868080938b40179efa20a8a0d5d009\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-e352e5f957839a7879aeeae1aa65ab60\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"emotion_zone\", \"scale\": {\"domain\": [\"green\", \"yellow\", \"red\", \"blue\"], \"range\": [\"green\", \"yellow\", \"red\", \"blue\"]}, \"title\": \"Emotion zones\", \"type\": \"nominal\"}, \"column\": {\"field\": \"video_part\", \"title\": \"Video Part - Session 1\", \"type\": \"nominal\"}, \"x\": {\"field\": \"emotion_zone\", \"sort\": [\"green\", \"yellow\", \"red\", \"blue\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"values\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-e352e5f957839a7879aeeae1aa65ab60\": [{\"video_part\": 1, \"emotion_zone\": \"green\", \"values\": 1296}, {\"video_part\": 2, \"emotion_zone\": \"green\", \"values\": 981}, {\"video_part\": 3, \"emotion_zone\": \"green\", \"values\": 1235}, {\"video_part\": 4, \"emotion_zone\": \"green\", \"values\": 317}, {\"video_part\": 5, \"emotion_zone\": \"green\", \"values\": 398}, {\"video_part\": 6, \"emotion_zone\": \"green\", \"values\": 501}, {\"video_part\": 7, \"emotion_zone\": \"green\", \"values\": 430}, {\"video_part\": 1, \"emotion_zone\": \"blue\", \"values\": 102}, {\"video_part\": 2, \"emotion_zone\": \"blue\", \"values\": 510}, {\"video_part\": 3, \"emotion_zone\": \"blue\", \"values\": 80}, {\"video_part\": 4, \"emotion_zone\": \"blue\", \"values\": 540}, {\"video_part\": 5, \"emotion_zone\": \"blue\", \"values\": 942}, {\"video_part\": 6, \"emotion_zone\": \"blue\", \"values\": 982}, {\"video_part\": 7, \"emotion_zone\": \"blue\", \"values\": 0}, {\"video_part\": 1, \"emotion_zone\": \"yellow\", \"values\": 33}, {\"video_part\": 2, \"emotion_zone\": \"yellow\", \"values\": 10}, {\"video_part\": 3, \"emotion_zone\": \"yellow\", \"values\": 38}, {\"video_part\": 4, \"emotion_zone\": \"yellow\", \"values\": 402}, {\"video_part\": 5, \"emotion_zone\": \"yellow\", \"values\": 161}, {\"video_part\": 6, \"emotion_zone\": \"yellow\", \"values\": 18}, {\"video_part\": 7, \"emotion_zone\": \"yellow\", \"values\": 126}, {\"video_part\": 1, \"emotion_zone\": \"red\", \"values\": 0}, {\"video_part\": 2, \"emotion_zone\": \"red\", \"values\": 0}, {\"video_part\": 3, \"emotion_zone\": \"red\", \"values\": 148}, {\"video_part\": 4, \"emotion_zone\": \"red\", \"values\": 242}, {\"video_part\": 5, \"emotion_zone\": \"red\", \"values\": 0}, {\"video_part\": 6, \"emotion_zone\": \"red\", \"values\": 0}, {\"video_part\": 7, \"emotion_zone\": \"red\", \"values\": 0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pandas function to transform from wide format to long format, so Altair can work better\n",
    "source = df.melt(\"video_part\", var_name=\"emotion_zone\", value_name='values')\n",
    "\n",
    "alt.Chart(source).mark_bar().encode(\n",
    "    alt.X('emotion_zone:N', sort=COLOURS),\n",
    "    alt.Y('values:Q'),\n",
    "    column=alt.Column('video_part:N', title='Video Part - Session 1'),\n",
    "    color=alt.Color('emotion_zone', scale=alt.Scale(domain=EMOTIONS, range=COLOURS), title='Emotion zones')\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f82b781",
   "metadata": {},
   "source": [
    "# Emotion Zones distribution over session 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0eb8006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-b12947c619ec427e9f27d5edc32ef49c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b12947c619ec427e9f27d5edc32ef49c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b12947c619ec427e9f27d5edc32ef49c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-c5e05e23f3dbb632e6d4f81d50c198a3\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"emotion_zone\", \"scale\": {\"domain\": [\"green\", \"yellow\", \"red\", \"blue\"], \"range\": [\"green\", \"yellow\", \"red\", \"blue\"]}, \"title\": \"Emotion zones\", \"type\": \"nominal\"}, \"column\": {\"field\": \"video_part\", \"title\": \"Video Part - Session 2.1\", \"type\": \"nominal\"}, \"x\": {\"field\": \"emotion_zone\", \"sort\": [\"green\", \"yellow\", \"red\", \"blue\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"values\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-c5e05e23f3dbb632e6d4f81d50c198a3\": [{\"video_part\": 1, \"emotion_zone\": \"green\", \"values\": 1224}, {\"video_part\": 2, \"emotion_zone\": \"green\", \"values\": 754}, {\"video_part\": 3, \"emotion_zone\": \"green\", \"values\": 325}, {\"video_part\": 4, \"emotion_zone\": \"green\", \"values\": 0}, {\"video_part\": 5, \"emotion_zone\": \"green\", \"values\": 752}, {\"video_part\": 6, \"emotion_zone\": \"green\", \"values\": 609}, {\"video_part\": 1, \"emotion_zone\": \"blue\", \"values\": 0}, {\"video_part\": 2, \"emotion_zone\": \"blue\", \"values\": 290}, {\"video_part\": 3, \"emotion_zone\": \"blue\", \"values\": 142}, {\"video_part\": 4, \"emotion_zone\": \"blue\", \"values\": 603}, {\"video_part\": 5, \"emotion_zone\": \"blue\", \"values\": 351}, {\"video_part\": 6, \"emotion_zone\": \"blue\", \"values\": 0}, {\"video_part\": 1, \"emotion_zone\": \"yellow\", \"values\": 241}, {\"video_part\": 2, \"emotion_zone\": \"yellow\", \"values\": 249}, {\"video_part\": 3, \"emotion_zone\": \"yellow\", \"values\": 804}, {\"video_part\": 4, \"emotion_zone\": \"yellow\", \"values\": 566}, {\"video_part\": 5, \"emotion_zone\": \"yellow\", \"values\": 377}, {\"video_part\": 6, \"emotion_zone\": \"yellow\", \"values\": 207}, {\"video_part\": 1, \"emotion_zone\": \"red\", \"values\": 36}, {\"video_part\": 2, \"emotion_zone\": \"red\", \"values\": 208}, {\"video_part\": 3, \"emotion_zone\": \"red\", \"values\": 230}, {\"video_part\": 4, \"emotion_zone\": \"red\", \"values\": 332}, {\"video_part\": 5, \"emotion_zone\": \"red\", \"values\": 21}, {\"video_part\": 6, \"emotion_zone\": \"red\", \"values\": 0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all dataframes (session 2.1)\n",
    "\n",
    "df_21_1 = pd.read_csv('datasets/participant_2_1/study_01_11_2021_01.mp4.csv')\n",
    "df_21_2 = pd.read_csv('datasets/participant_2_1/study_01_11_2021_02.mp4.csv')\n",
    "df_21_3 = pd.read_csv('datasets/participant_2_1/study_01_11_2021_03.mp4.csv')\n",
    "df_21_4 = pd.read_csv('datasets/participant_2_1/study_01_11_2021_04.mp4.csv')\n",
    "df_21_5 = pd.read_csv('datasets/participant_2_1/study_01_11_2021_05.mp4.csv')\n",
    "df_21_6 = pd.read_csv('datasets/participant_2_1/study_01_11_2021_06.mp4.csv')\n",
    "\n",
    "dataframes_21 = [df_21_1, df_21_2, df_21_3, df_21_4, df_21_5, df_21_6]\n",
    "\n",
    "dataframes_21 = add_video_part_column_to_dataframes(dataframes_21)\n",
    "\n",
    "dataframes_21_dict = create_whole_session_dict_values(dataframes_21)\n",
    "\n",
    "\n",
    "df_session_21 = pd.DataFrame(dataframes_21_dict)\n",
    "\n",
    "\n",
    "# Using pandas function to transform from wide format to long format, so Altair can work better\n",
    "source_21 = df_session_21.melt(\"video_part\", var_name=\"emotion_zone\", value_name='values')\n",
    "\n",
    "alt.Chart(source_21).mark_bar().encode(\n",
    "    alt.X('emotion_zone:N', sort=COLOURS),\n",
    "    alt.Y('values:Q'),\n",
    "    column=alt.Column('video_part:N', title='Video Part - Session 2.1'),\n",
    "    color=alt.Color('emotion_zone', scale=alt.Scale(domain=EMOTIONS, range=COLOURS), title='Emotion zones')\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0030f",
   "metadata": {},
   "source": [
    "# Emotion Zones distribution over session 2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f497715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-b2f8b834e7724fcaa55d32ec050fb8c6\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b2f8b834e7724fcaa55d32ec050fb8c6\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b2f8b834e7724fcaa55d32ec050fb8c6\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-90904183f2757defbf6b37ae8b7cd92d\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"emotion_zone\", \"scale\": {\"domain\": [\"green\", \"yellow\", \"red\", \"blue\"], \"range\": [\"green\", \"yellow\", \"red\", \"blue\"]}, \"title\": \"Emotion zones\", \"type\": \"nominal\"}, \"column\": {\"field\": \"video_part\", \"title\": \"Video Part - Session 2.2\", \"type\": \"nominal\"}, \"x\": {\"field\": \"emotion_zone\", \"sort\": [\"green\", \"yellow\", \"red\", \"blue\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"values\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-90904183f2757defbf6b37ae8b7cd92d\": [{\"video_part\": 1, \"emotion_zone\": \"green\", \"values\": 1501}, {\"video_part\": 2, \"emotion_zone\": \"green\", \"values\": 347}, {\"video_part\": 3, \"emotion_zone\": \"green\", \"values\": 879}, {\"video_part\": 4, \"emotion_zone\": \"green\", \"values\": 301}, {\"video_part\": 5, \"emotion_zone\": \"green\", \"values\": 897}, {\"video_part\": 6, \"emotion_zone\": \"green\", \"values\": 550}, {\"video_part\": 1, \"emotion_zone\": \"blue\", \"values\": 0}, {\"video_part\": 2, \"emotion_zone\": \"blue\", \"values\": 0}, {\"video_part\": 3, \"emotion_zone\": \"blue\", \"values\": 249}, {\"video_part\": 4, \"emotion_zone\": \"blue\", \"values\": 1142}, {\"video_part\": 5, \"emotion_zone\": \"blue\", \"values\": 192}, {\"video_part\": 6, \"emotion_zone\": \"blue\", \"values\": 51}, {\"video_part\": 1, \"emotion_zone\": \"yellow\", \"values\": 0}, {\"video_part\": 2, \"emotion_zone\": \"yellow\", \"values\": 501}, {\"video_part\": 3, \"emotion_zone\": \"yellow\", \"values\": 373}, {\"video_part\": 4, \"emotion_zone\": \"yellow\", \"values\": 58}, {\"video_part\": 5, \"emotion_zone\": \"yellow\", \"values\": 412}, {\"video_part\": 6, \"emotion_zone\": \"yellow\", \"values\": 0}, {\"video_part\": 1, \"emotion_zone\": \"red\", \"values\": 0}, {\"video_part\": 2, \"emotion_zone\": \"red\", \"values\": 653}, {\"video_part\": 3, \"emotion_zone\": \"red\", \"values\": 0}, {\"video_part\": 4, \"emotion_zone\": \"red\", \"values\": 0}, {\"video_part\": 5, \"emotion_zone\": \"red\", \"values\": 0}, {\"video_part\": 6, \"emotion_zone\": \"red\", \"values\": 0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all dataframes (session 2.2)\n",
    "\n",
    "df_22_1 = pd.read_csv('datasets/participant_2_2/study_08112021_session_02_02_01.mp4.csv')\n",
    "df_22_2 = pd.read_csv('datasets/participant_2_2/study_08112021_session_02_02_02.mp4.csv')\n",
    "df_22_3 = pd.read_csv('datasets/participant_2_2/study_08112021_session_02_02_03.mp4.csv')\n",
    "df_22_4 = pd.read_csv('datasets/participant_2_2/study_08112021_session_02_02_04.mp4.csv')\n",
    "df_22_5 = pd.read_csv('datasets/participant_2_2/study_08112021_session_02_02_05.mp4.csv')\n",
    "df_22_6 = pd.read_csv('datasets/participant_2_2/study_08112021_session_02_02_06.mp4.csv')\n",
    "\n",
    "\n",
    "dataframes_22 = [df_22_1, df_22_2, df_22_3, df_22_4, df_22_5, df_22_6]\n",
    "\n",
    "dataframes_22 = add_video_part_column_to_dataframes(dataframes_22)\n",
    "\n",
    "dataframes_22_dict = create_whole_session_dict_values(dataframes_22)\n",
    "\n",
    "\n",
    "df_session_22 = pd.DataFrame(dataframes_22_dict)\n",
    "\n",
    "\n",
    "# Using pandas function to transform from wide format to long format, so Altair can work better\n",
    "source_22 = df_session_22.melt(\"video_part\", var_name=\"emotion_zone\", value_name='values')\n",
    "\n",
    "alt.Chart(source_22).mark_bar().encode(\n",
    "    alt.X('emotion_zone:N', sort=COLOURS),\n",
    "    alt.Y('values:Q'),\n",
    "    column=alt.Column('video_part:N', title='Video Part - Session 2.2'),\n",
    "    color=alt.Color('emotion_zone', scale=alt.Scale(domain=EMOTIONS, range=COLOURS), title='Emotion zones')\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
